
<h1> ğŸ—ï¸ Insurance Data ETL Pipeline </h1>


<h2>ğŸ“Œ Project Overview</h2>
This project is a modular, production-ready ETL pipeline built in Python for cleaning, transforming, and loading insurance-related data into a PostgreSQL database. It extracts data from Postgre Database, applies industry-standard data cleaning steps, and loads it into a cleaned schema for downstream analytics or BI use.

<h2> ğŸš€ Key Features </h2>

- ğŸ” Extracts data from PostgreSQL tables

- ğŸ§¹ Applies data cleaning:
    - Column standardization
    - Type casting
    - Null handling
    - Text normalization
    - Duplicate removal

- ğŸ” Modular transformation functions

- ğŸ›¢ï¸ Loads clean data into new PostgreSQL tables

- ğŸ“œ Centralized logging with timestamps for monitoring



<h2>ğŸ§° Tech Stack </h2>

- Python 3.8+
- Pandas for data manipulation
- SQLAlchemy for PostgreSQL connectivity
- Logging module for structured pipeline tracking
- PostgreSQL as target data warehouse


<h2>ğŸ› ï¸ Recommended Tools</h2>

- VS Code (with Python and Jupyter extensions)

- DBeaver or pgAdmin for interacting with PostgreSQL

- Git for version control

<h2> ğŸ“ Log outputs </h2>

<img src="https://i.imgur.com/8b3Hh08.png" alt=" ETL_Automation Folder" width="600"/>

<h2> ğŸ‘¤ Author / Contact </h2>

<b>Simon Muriu</b> 
<b>Data Analyst</b>  
[LinkedIn](https://www.linkedin.com/in/simon-muriu-0a1310251/) | 
[Email](mailto:smuriu06@gmail.com)


<!--
 ```diff
- text in red
+ text in green
! text in orange
# text in gray
@@ text in purple (and bold)@@
```
--!>
