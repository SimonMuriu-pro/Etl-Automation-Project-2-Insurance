
<h1> 🏗️ Insurance Data ETL Pipeline </h1>


<h2>📌 Project Overview</h2>
This project is a modular, production-ready ETL pipeline built in Python for cleaning, transforming, and loading insurance-related data into a PostgreSQL database. It extracts data from Postgre Database, applies industry-standard data cleaning steps, and loads it into a cleaned schema for downstream analytics or BI use.

<h2> 🚀 Key Features </h2>

- 🔍 Extracts data from PostgreSQL tables

- 🧹 Applies data cleaning:
    - Column standardization
    - Type casting
    - Null handling
    - Text normalization
    - Duplicate removal

- 🔁 Modular transformation functions

- 🛢️ Loads clean data into new PostgreSQL tables

- 📜 Centralized logging with timestamps for monitoring



<h2>🧰 Tech Stack </h2>

- Python 3.8+
- Pandas for data manipulation
- SQLAlchemy for PostgreSQL connectivity
- Logging module for structured pipeline tracking
- PostgreSQL as target data warehouse


<h2>🛠️ Recommended Tools</h2>

- VS Code (with Python and Jupyter extensions)

- DBeaver or pgAdmin for interacting with PostgreSQL

- Git for version control

<h2> 📁 Log outputs </h2>

<img src="https://i.imgur.com/8b3Hh08.png" alt=" ETL_Automation Folder" width="600"/>

<h2> 👤 Author / Contact </h2>

<b>Simon Muriu</b> 
<b>Data Analyst</b>  
[LinkedIn](https://www.linkedin.com/in/simon-muriu-0a1310251/) | 
[Email](mailto:smuriu06@gmail.com)


<!--
 ```diff
- text in red
+ text in green
! text in orange
# text in gray
@@ text in purple (and bold)@@
```
--!>
